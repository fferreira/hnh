\documentclass[a4paper, 12pt]{article}
\usepackage[applemac]{inputenc}
\usepackage{textcomp}



\title{HNH Report}
\author{
        Francisco Ferreira \\
                FERF13027601\\
}

\date{\today}


\begin{document}
\maketitle

\section {Introduction}
\subsection{The Name}
In the grand GNU tradition the HNH name is a recursive acronym. Standing for “HNH’s not Haskell”. More than homage to the Free Software Foundation’s project this is a consequence of the huge task that would be to implement a proper Haskell compiler. So if HNH pretended to be the full language implementation the limitations section would certainly exceed the maximum ten pages allocated to it. It is important to notice that the discussions of the limitations of the current implementation will probably take a commanding share of the available space.

\subsection {Using the compiler}
After a successful make, the executable hnh is generated. The usage is as follows:

\texttt{ ./hnh  <cmd> <program source> }

where the supported comands are:

\begin{tabular}{| p{6cm} | p{6cm} | } 
\hline
\textbf{Command} & \textbf{Description} \\
\hline
\texttt {c} & compile to code.c \\
\hline
\texttt {cd} & compile to code.c and print all code transformations\\
\hline
\end{tabular}



In order to execute the included sample one needs to call:

\begin{center} \texttt{./hnh c qsort.hnh} \end{center}

This will print any errors found during the compilation process, or if no errors are found it will compile the code to the file code.c. If the cd command is used, the result of each of the 14 stages of compilation will be printed to the console for debugging purposes.

Finally the command \texttt{ make runtime \&\& ./runtime } is used to produce the final executable and execute it.

\section{The Language}

Even not being Haskell by definition, HNH shares a lot of things with Haskell; the table~\ref{comparison} shows the more important bullet points of the similarities and differences.

\begin{table} 
\begin{tabular}{| p{6cm} | p{6cm} | } 
\hline
\textbf{Like Haskell} & \textbf{Unlike Haskell} \\
\hline
It’s a functional language & It’s strict \\
It’s pure & No type classes \\
It shares many syntactic elements of Haskell & Pattern matching is severely simplified (even limited) \\
Supports user defined operators with specified precedence and associativity & No guards for functions \\
 & Diminutive prelude \\
\hline
\end{tabular}
\caption{Haskel and HNH compared}\label{comparison}
\end{table}

\subsection{The Lexical Structure}
HNH lexical structure is mainly based in that from the Haskell Report\cite{haskell-report} but some keywords are not part of the language. Block and line comments are now supported (only line comments were supported in the interpreter).

\subsubsection{Reserved words}

The supported list of reserved words is \texttt{infix infixl infixr data type if then else let in case of}. None of these words may be used as an identifier or function name.

\subsubsection{Variables,operators and type constructors} \label{varops}

Variables are the valid identifier names of the language and consist of a sequence of latin letters (a to z) and ' beginning with a small case letter.

Constructors are the valid identifiers for types and type constructors and consist of a sequence of latin letters (a to z) and ' beginning with a big case letter.

As HNH supports user-defined operators, that are a sequence of one or more of: ``\texttt{! \textasciicircum \# \$ \% \& * + . - \textasciitilde / \textbackslash | < = > ? @}''

\subsubsection{Literals}

HNH recognizes literals of four types (besides tuples and lists that will be discussed in the syntax section) integers, floating point numbers, strings and characters.

Integers can be expressed in either base 10 or base 8 by prefixing the number with \texttt{0o} or \texttt{0O} or base 16 by prefixing them with \texttt{0x} or \texttt{0X} and using small or big case letters from \texttt{a} to \texttt{f} for the hex digits. Negative integers use the \textasciitilde as unary negation operator.

Float numbers, internally represented as Haskell's Doubles, as usual with other languages are composed of a mantissa and an exponent. The exponent can be absent, and negative exponents use the - sign, but negative floating point numbers are indicated with \textasciitilde. (a tilde and a dot)

While Strings and Chars are similar to Haskell's, a String uses double quotes as delimiters where a Char uses single quotes.

\subsection{HNH’s Syntax}
\subsubsection{Type declarations}
For user defined types, there is support for two constructs, type synonyms, and algebraic datatypes (\texttt{data} declarations). Type synonyms are declared with the \texttt{type} keyword. Note that in the current version of the compiler type synonyms are parsed but not used by the compiler.

\begin{center}
	\texttt{ type T $u_{1} \dots u_{k}$ = $t$ }
\end{center}

Where T is the new name for the type $t$ and $u_{k}$ are $t$'s parameters. The current implementation of the interpreter ignores these declarations as it is dynamically typed.

Algebraic type declarations use the \texttt{data} keyword and have the form:

\begin{center}
	\texttt{data T $u_{1} \dots u_{k}$ = $K_{1} t_{11} \dots t_{1k_{1}} | \dots | K_{n} t_{n1} \dots t_{nk_{n}} $}
\end{center}

Where T is the new declared type and $K_{1} \dots K_{n}$ are the different constructors and its parameters.

For instance the two built in types Bool and List are declared as follows

\texttt { data Bool = True | False ;}

\texttt { data List a = Cons a List | Nil ;}

\subsubsection{Patterns}\label{patterns}

The core of a program are function and variable declarations, both use the concept of patterns. Patterns in HNH are very simple version compared to those from Haskell.
Patterns can be:
\begin{itemize}
  \item A simple variable name that matches any value
  \item A type constructor that matches its parameters (i.e. (Cons d rest) matches d to the head of the List and rest to the tail of the list)
  \item (d:rest) matches to a list and bind d to the head and rest to the tail, it can be considered syntactic sugar for the previous example
  \item $[]$ Matches the empty list and produces no variable bindings
  \item \_ matches anything but produces no bindings
  \item (a, b) matches to a tuple and binds a to the first element and b to the second, tuples can have an arbitrary number of elements

\end{itemize}

Parameters can not contain other patterns, it is not possible to match (Cons a Nil) to the list of one element. This is the main simplification with respect to Haskell's patterns, other differences include the lack of list parameters and the \@ patterns.

\subsubsection{Functions and variables}

A function declaration is:

$x \:;p_{11} \dots p_{1k} = e$;

\dots

$x \; p_{n1} \dots p_{nk} = e$; 

where $x$ is the name of the functions and the $p$'s are the different patterns.

Variable definition is simpler:

$ pattern = e $;

\subsubsection {User defined operators}

User defined operators are sequences of one or more symbols as per section~\ref{varops}. The precedence and associativity are declared with the \texttt{infix, infixr, infixl} exactly in they Haskell does. Operators can be used where variables are required by surrounding them in parenthesis, and functions can be used \emph{infix} by surrounding them with backquotes.
One limitation is that \emph{fixity} declarations can only be used in the top-level. Currently the prelude declares the precedence and associativity of the built-in operators which have no built-in precedence otherwise.

\subsubsection {Expressions}

Expressions are similar to Haskell's
\begin{itemize}
  \item \texttt{let}, \texttt{case},\texttt{if}, \texttt{case} expressions
  \item lambda expressions with the same pattern restriction as function declarations
  \item function applications and infix operators are also unchanged, only that currying infix operators require surrounding them with parenthesis
\end{itemize}

\subsubsection{Type declarations}

Type declarations in symbol declarations are parsed but not used, the only type declarations are done by enclosing an expression in parenthesis and annotating the type. (i.e. \texttt{(exp :: type)}).

\subsubsection{Semicolons everywhere!}

HNH does not support the layout rules of Haskell expressions and declarations have to be separated with a semicolon. $ \{\;\} $ braces are used in \texttt{let} and \texttt{case} expressions too.

\subsection{The Implementation}
The compiler is implemented in 14 phases not counting the integrated lexing and parsing.

The lexing phase and the parsing phase are integrated and implemented using Parsec in the file Parser.hs. The parser is implemented in a rather straightforward (i.e. simplistic) way, this makes it easy to understand, easy to debug and easy to extend. One of the notable limitations of this parser is the cryptic error reports. Better error reports shouldn't be difficult (though time demanding) to implement given the simplicity of the current implementation.

\subsubsection{Code Transformations}

Fourteen simple transformations are currently done to the parsed program:
\begin{itemize}
	\item \texttt{correctPrecedence} which corrects the precedence of the operators
	\item \texttt{toPrefix} which converts infix operations to function calls
	\item \texttt{funToLambda} which converts all function declarations to lambda expressions
	\item \texttt{simplifyLambda} which simplifies the patterns in the lambda expressions with the restrictions mentioned in section~\ref{patterns}
	\item \texttt{oneVarLambda} which transforms all the lambda expressions in one parameter lambda expressions
	\item \texttt{addIdentifiers} which replaces variable names by unique identifiers
	\item \texttt{performTypeInference} which, rather obviously, performs type inference
	\item \texttt{progToLet} which transforms the program to a single expression (i.e. \texttt{main = let $\ldots$})
	\item \texttt{cpsTransform} as the name implies performs a CPS transformation
	\item \texttt{removeVarK} which removes VarK nodes as they are not needed
	\item \texttt{closureConversion} surprisingly this phase does the Closure Conversion of the code to eliminate free variables in functions
	\item \texttt{codeGen} this phase performs hoisting and the C code generation
\end{itemize}

To implement the transformations, there is a monad \texttt{TransformM} in TransformMonad.hs that greatly simplifies writing code transformations that don't require keeping track of the environment.

\subsubsection{Code Transformations (The highlights)}

The compilation phases can be grouped according to its purpose. The first 6 phases (including addIdentifiers) prepare and simplify the program, eliminating some syntactic sugar and leaving a simpler program representation though a more verbose one.

PerformTypeInference, will then infer the types supporting polymorphism, without type classes or overloading thus the need for different operators for different types (i.e. + and +.). qsort.hnh contains a simple example of polymorphic functions.

After validating the typing of the program the code is generated in a straightforward way CPS Conversion \textrightarrow Closure Conversion \textrightarrow Code Generation. The almost complete lack of optimizations generates a very naïve code, the only optimization is the elimination of VarK nodes that only rename variables. Simple optimizations like inlining all functions called only once would improve the quality of the generated code. It's important to notice that even if they are not implemented, the compiler structure is prepared to host those optimizations without having to introduce big changes.

\subsubsection{Code Representation}

Two code different types are used. \texttt{Program} from Syntax.hs before the CPS transformation and \texttt{KExp} from CPSRep.hs that is used after CPS conversion. Once the program passes the type inference inference the typing information is no longer used.

One thing that would improve code readability would be to use an extra representation, that would be introduced after oneVarLambda, as at this point the program has been transformed to used a subset of the features of the original, and it would help diminish some boilerplate code afterwards.

Additionally, typing information would be helpful after CPS conversion to help improve the runtime representation of values by eliminating the need for some boxing.

\subsection{The Runtime}

The runtime representation is fully boxed, and uses \texttt{value *} to represent a value. A \texttt{value} contains a \texttt{tag} field with the type and a union field with the representation of the stored value. A better representation with more efficient tagging and less indirections could greatly improve performance, and this would not be difficult to add to the runtime by only modifying the c code.
The \texttt{main} symbol is evaluated and its result is printed by the the final continuation \texttt{HaltK}, the runtime contains printing facilites that print lists, strings, tuples and values in general, so the result will be the value of the symbol main. If this value is a function, the memory address of the function will be printed.
The typing information is discarded in the CPS conversion, but as the program was deemed correct then, no type checks are needed (though some asserts are present in the code for debugging purposes).

Each function in the CPS form is compiled to a separate function and in order to avoid the exhaustion of the call stack a trampoline is used in the main function, where each called function never calls another but returns the address of the next.

\subsection{Built-ins and the prelude}

Several low level operations are implemented as intrinsic, all of them can be found in BuiltIn.hs. Here the compiler defines arithmetic and compare operations, are and the List and Bool types. This is intended to be minimal, as the operations could not be implemented in HNH, and the built in types are used by the syntax of the language (i.e. pattern matching, and if expressions). The arithmetic operations is not absolutely minimal for performance purposes as for example defining the multiplication as a sequence of additions would be unnecessarily slow.

The prelude can be found in prelude.hnh and is loaded before the source of the program, and contains several utility functions, in its current form is not very complete, but the current functions suffice for the sample program.


\subsection{The Garbage Collector}

The algorithm used is Stop \& Copy. The garbage collector uses three memory zones, one for global, permanent objects, a front segment and back segment. When a garbage collection is triggered in the trampoline, the segments are swapped and all the alive objects are copied from the from the back page to the front page. Then the back segment is emptied. The objects in the permanent segment are never garbage collected. The roots are the parameters to the function that include the closure, and the continuation.
Additionally all the configuration parameters for memory management are in the file config.h.

\subsection{Conclusion}

The idea of sequentially transforming the code, the use of powerful techniques as type inference, and CPS and Closure conversion have made possible this compiler, even if most things were done in a simplistic way. I think that the resulting compiler uses many techniques and has allowed me to learn a lot by implementing the code, and by deciding what to leave out (better error reporting, typed CPS conversion, code optimizations, better closures, a more compact runtime representation, and the list goes on and on). The resulting compiler is simple to understand and simple to extend, and I am very happy with what I learned and with the result (which may be not ready yet to compile code for medical equipment but it was a great vehicle for learning).

\subsection{Odds and Ends}
The code is also available online at http://www.github.com/fferreira/hnh under the GPL license.


\bibliographystyle{plain}
\bibliography{bibliography} 

\end{document}


